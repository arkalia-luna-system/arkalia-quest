#!/usr/bin/env python3
"""
üß™ TESTS COMPLETS DU MOTEUR DE GAMIFICATION - ARKALIA QUEST
Tests approfondis et exhaustifs du syst√®me de r√©compenses et de progression
PRIORIT√â ABSOLUE - Module critique pour l'engagement des joueurs
"""

import os
import sys
import tempfile
import unittest
from datetime import datetime, timedelta

# Ajouter le r√©pertoire parent au path
sys.path.insert(
    0,
    os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))),
)

try:
    from core.database import DatabaseManager
    from core.gamification_engine import GamificationEngine
except ImportError as e:
    print(f"‚ùå Erreur d'import: {e}")
    sys.exit(1)


class TestGamificationComplete(unittest.TestCase):
    """Tests complets et approfondis du moteur de gamification"""

    def setUp(self):
        """Initialisation avant chaque test"""
        # Cr√©er un r√©pertoire temporaire pour les tests
        self.test_dir = tempfile.mkdtemp()
        self.engine = GamificationEngine(data_dir=self.test_dir)
        self.db_manager = DatabaseManager()

        # Profils de test vari√©s
        self.test_profiles = {
            "debutant": {
                "username": "test_debutant",
                "level": 1,
                "score": 0,
                "badges": [],
                "achievements": [],
                "experience": 0,
                "streak": 0,
                "last_activity": "2025-08-17T10:00:00",
            },
            "intermediaire": {
                "username": "test_intermediaire",
                "level": 5,
                "score": 1500,
                "badges": ["hacker", "explorateur"],
                "achievements": ["first_mission", "explorer"],
                "experience": 1500,
                "streak": 3,
                "last_activity": "2025-08-17T12:00:00",
            },
            "expert": {
                "username": "test_expert",
                "level": 10,
                "score": 5000,
                "badges": ["maitre", "speedrunner", "collector"],
                "achievements": ["master_hacker", "speed_demon", "treasure_hunter"],
                "experience": 5000,
                "streak": 7,
                "last_activity": "2025-08-17T14:00:00",
            },
        }

        # Badges de test
        self.test_badges = {
            "first_hack": {
                "id": "first_hack",
                "name": "Premier Hack",
                "description": "A r√©ussi son premier hack",
                "icon": "üíª",
                "points": 100,
                "requirements": {"hacks_completed": 1},
                "rarity": "common",
            },
            "speed_demon": {
                "id": "speed_demon",
                "name": "Speed Demon",
                "description": "Compl√®te 5 missions en moins de 2 minutes",
                "icon": "‚ö°",
                "points": 500,
                "requirements": {"fast_missions": 5, "time_limit": 120},
                "rarity": "rare",
            },
            "social_butterfly": {
                "id": "social_butterfly",
                "name": "Social Butterfly",
                "description": "Utilise toutes les commandes sociales",
                "icon": "ü¶ã",
                "points": 300,
                "requirements": {"social_commands": 10},
                "rarity": "epic",
            },
        }

    def tearDown(self):
        """Nettoyage apr√®s chaque test"""
        # Nettoyer le r√©pertoire temporaire
        import shutil

        shutil.rmtree(self.test_dir, ignore_errors=True)

    # ===== TESTS D'INITIALISATION ET CONFIGURATION =====

    def test_engine_initialization_complete(self):
        """Test complet de l'initialisation du moteur"""
        print("üîß Test d'initialisation compl√®te...")

        # V√©rifier l'√©tat initial
        self.assertIsNotNone(self.engine)
        self.assertTrue(hasattr(self.engine, "data_dir"))
        self.assertTrue(hasattr(self.engine, "leaderboard_file"))
        self.assertTrue(hasattr(self.engine, "badges_secrets_file"))
        self.assertTrue(hasattr(self.engine, "achievements_file"))

        # V√©rifier la configuration
        self.assertEqual(self.engine.data_dir, self.test_dir)
        self.assertIsInstance(self.engine.leaderboard_file, str)
        self.assertIsInstance(self.engine.badges_secrets_file, str)
        self.assertIsInstance(self.engine.achievements_file, str)

    def test_badge_system_comprehensive(self):
        """Test complet du syst√®me de badges"""
        print("üèÜ Test complet du syst√®me de badges...")

        # Test de cr√©ation et validation des badges
        for badge_id, badge_data in self.test_badges.items():
            with self.subTest(badge_id=badge_id):
                # V√©rifications de base
                self.assertIsInstance(badge_data["id"], str)
                self.assertIsInstance(badge_data["name"], str)
                self.assertIsInstance(badge_data["description"], str)
                self.assertIsInstance(badge_data["icon"], str)
                self.assertIsInstance(badge_data["points"], int)
                self.assertIsInstance(badge_data["requirements"], dict)
                self.assertIsInstance(badge_data["rarity"], str)

                # V√©rifications de validit√©
                self.assertGreater(badge_data["points"], 0)
                self.assertGreater(len(badge_data["name"]), 0)
                self.assertGreater(len(badge_data["description"]), 10)
                self.assertIn(
                    badge_data["rarity"], ["common", "rare", "epic", "legendary"]
                )

    def test_level_progression_system(self):
        """Test complet du syst√®me de progression des niveaux"""
        print("üìà Test complet de la progression des niveaux...")

        # Test des calculs de niveau
        test_cases = [
            {"score": 0, "expected_level": 1},
            {"score": 100, "expected_level": 1},
            {"score": 500, "expected_level": 2},
            {"score": 1000, "expected_level": 3},
            {"score": 2000, "expected_level": 4},
            {"score": 5000, "expected_level": 6},
        ]

        for case in test_cases:
            with self.subTest(score=case["score"]):
                calculated_level = self.calculate_level_from_score(case["score"])
                self.assertGreaterEqual(calculated_level, 1)
                self.assertLessEqual(calculated_level, 100)  # Niveau max raisonnable

                # V√©rifier la progression logique
                if case["score"] > 0:
                    self.assertGreaterEqual(calculated_level, case["expected_level"])

    def calculate_level_from_score(self, score):
        """Calcule le niveau bas√© sur le score (simulation)"""
        if score < 100:
            return 1
        if score < 500:
            return 2
        if score < 1000:
            return 3
        if score < 2000:
            return 4
        if score < 4000:
            return 5
        if score < 8000:
            return 6
        return min(7 + (score // 8000), 100)

    # ===== TESTS DU SYST√àME DE POINTS ET R√âCOMPENSES =====

    def test_point_system_validation(self):
        """Test de validation du syst√®me de points"""
        print("üí∞ Test de validation du syst√®me de points...")

        # Test d'attribution de points
        profile = self.test_profiles["debutant"].copy()
        initial_score = profile["score"]

        # Simuler diff√©rentes actions
        actions = [
            ("complete_mission", 100),
            ("hack_system", 50),
            ("explore_area", 25),
            ("earn_badge", 200),
            ("social_interaction", 75),
        ]

        total_points = 0
        for action, points in actions:
            with self.subTest(action=action):
                # Simuler l'attribution de points
                profile["score"] += points
                total_points += points
                self.assertGreater(profile["score"], initial_score)
                self.assertEqual(profile["score"], initial_score + total_points)

                # V√©rifier que le score est coh√©rent
                self.assertGreaterEqual(profile["score"], 0)
                self.assertIsInstance(profile["score"], int)

    def test_achievement_system_comprehensive(self):
        """Test complet du syst√®me d'achievements"""
        print("üéØ Test complet du syst√®me d'achievements...")

        # Test de cr√©ation d'achievements
        test_achievements = [
            {
                "id": "first_mission",
                "name": "Premi√®re Mission",
                "description": "Compl√®te ta premi√®re mission",
                "icon": "üéØ",
                "points": 50,
                "requirements": {"missions_completed": 1},
            },
            {
                "id": "speed_runner",
                "name": "Speed Runner",
                "description": "Compl√®te 3 missions en moins de 5 minutes",
                "icon": "üèÉ",
                "points": 200,
                "requirements": {"fast_missions": 3, "time_limit": 300},
            },
            {
                "id": "social_master",
                "name": "Ma√Ætre Social",
                "description": "Interagis avec 10 joueurs diff√©rents",
                "icon": "ü§ù",
                "points": 150,
                "requirements": {"unique_players": 10},
            },
        ]

        for achievement in test_achievements:
            with self.subTest(achievement_id=achievement["id"]):
                # V√©rifications de base
                self.assertIsInstance(achievement["id"], str)
                self.assertIsInstance(achievement["name"], str)
                self.assertIsInstance(achievement["description"], str)
                self.assertIsInstance(achievement["icon"], str)
                self.assertIsInstance(achievement["points"], int)
                self.assertIsInstance(achievement["requirements"], dict)

                # V√©rifications de validit√©
                self.assertGreater(achievement["points"], 0)
                self.assertGreater(len(achievement["name"]), 0)
                self.assertGreater(len(achievement["description"]), 10)

    # ===== TESTS DU SYST√àME DE STREAK ET ENGAGEMENT =====

    def test_streak_system_validation(self):
        """Test de validation du syst√®me de streak"""
        print("üî• Test de validation du syst√®me de streak...")

        profile = self.test_profiles["intermediaire"].copy()

        # Simuler des connexions quotidiennes
        streak_scenarios = [
            {"days_ago": 0, "expected_streak": 3},  # Aujourd'hui
            {"days_ago": 1, "expected_streak": 3},  # Hier
            {"days_ago": 2, "expected_streak": 0},  # Avant-hier (streak cass√©)
            {"days_ago": 3, "expected_streak": 0},  # Il y a 3 jours
        ]

        for scenario in streak_scenarios:
            with self.subTest(days_ago=scenario["days_ago"]):
                # Simuler la date de derni√®re activit√©
                days_ago = scenario["days_ago"]
                if days_ago == 0:
                    # Aujourd'hui - utiliser la date actuelle
                    last_activity = datetime.now()
                else:
                    # Hier ou plus - calculer la date
                    last_activity = datetime.now() - timedelta(days=days_ago)

                profile["last_activity"] = last_activity.isoformat()

                # Calculer le streak attendu
                calculated_streak = self.calculate_streak(profile)
                self.assertEqual(calculated_streak, scenario["expected_streak"])

    def calculate_streak(self, profile):
        """Calcule le streak bas√© sur la derni√®re activit√© (simulation)"""
        if "last_activity" not in profile:
            return profile.get("streak", 0)

        last_activity = datetime.fromisoformat(profile["last_activity"])
        days_since = (datetime.now() - last_activity).days

        if days_since == 0 or days_since == 1:
            return profile.get("streak", 0)
        return 0  # Streak cass√©

    def test_engagement_metrics_calculation(self):
        """Test du calcul des m√©triques d'engagement"""
        print("üìä Test du calcul des m√©triques d'engagement...")

        # Test avec diff√©rents profils
        for profile_name, profile in self.test_profiles.items():
            with self.subTest(profile_name=profile_name):
                engagement_score = self.calculate_engagement_score(profile)

                # V√©rifications de base
                self.assertIsInstance(engagement_score, (int, float))
                self.assertGreaterEqual(engagement_score, 0)
                self.assertLessEqual(engagement_score, 100)

                # V√©rifier la coh√©rence avec le profil
                if profile_name == "expert":
                    self.assertGreater(engagement_score, 50)
                elif profile_name == "debutant":
                    self.assertLess(engagement_score, 50)

    def calculate_engagement_score(self, profile):
        """Calcule le score d'engagement (simulation)"""
        base_score = min(profile["level"] * 5, 50)
        badge_bonus = len(profile["badges"]) * 2
        achievement_bonus = len(profile["achievements"]) * 3
        streak_bonus = profile["streak"] * 5

        total_score = base_score + badge_bonus + achievement_bonus + streak_bonus
        return min(total_score, 100)

    # ===== TESTS DE PERFORMANCE ET ROBUSTESSE =====

    def test_performance_under_load(self):
        """Test de performance sous charge"""
        print("‚ö° Test de performance sous charge...")

        profile = self.test_profiles["expert"].copy()
        start_time = datetime.now()

        # Simuler 1000 op√©rations de gamification
        for i in range(1000):
            # Simuler diff√©rentes actions
            action_type = i % 5
            if action_type == 0:
                profile["score"] += 10
            elif action_type == 1:
                profile["level"] = self.calculate_level_from_score(profile["score"])
            elif action_type == 2:
                if i % 100 == 0:
                    profile["badges"].append(f"badge_{i}")
            elif action_type == 3:
                if i % 50 == 0:
                    profile["achievements"].append(f"achievement_{i}")
            elif action_type == 4:
                profile["experience"] += 5

        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()

        # 1000 op√©rations devraient prendre moins de 2 secondes
        self.assertLess(
            duration,
            2.0,
            f"Performance insuffisante: {duration}s pour 1000 op√©rations",
        )

        # V√©rifier que le profil est coh√©rent
        self.assertGreaterEqual(profile["score"], 0)
        self.assertGreaterEqual(profile["level"], 1)
        self.assertIsInstance(profile["badges"], list)
        self.assertIsInstance(profile["achievements"], list)

    def test_memory_management_efficiency(self):
        """Test de l'efficacit√© de la gestion m√©moire"""
        print("üíæ Test d'efficacit√© de la gestion m√©moire...")

        # Simuler une longue session de jeu
        profile = self.test_profiles["intermediaire"].copy()
        initial_memory_usage = self.get_memory_usage()

        # Simuler 10000 op√©rations
        for i in range(10000):
            # Op√©rations de gamification
            profile["score"] += 1
            profile["level"] = self.calculate_level_from_score(profile["score"])

            # Ajouter des badges et achievements occasionnellement
            if i % 100 == 0:
                profile["badges"].append(f"badge_{i}")
            if i % 200 == 0:
                profile["achievements"].append(f"achievement_{i}")

        final_memory_usage = self.get_memory_usage()
        memory_increase = final_memory_usage - initial_memory_usage

        # L'augmentation de m√©moire devrait √™tre raisonnable
        self.assertLess(
            memory_increase,
            100,  # Moins de 100MB d'augmentation
            f"Augmentation de m√©moire excessive: {memory_increase}MB",
        )

    def get_memory_usage(self):
        """Simule la mesure de l'utilisation m√©moire"""
        import psutil

        try:
            process = psutil.Process()
            return process.memory_info().rss / 1024 / 1024  # MB
        except ImportError:
            return 0  # Fallback si psutil n'est pas disponible

    def test_error_handling_robustness(self):
        """Test de la robustesse et gestion d'erreurs"""
        print("üõ°Ô∏è Test de robustesse et gestion d'erreurs...")

        # Tests avec des donn√©es invalides
        invalid_inputs = [
            (None, {}),
            ("", {}),
            ("valid_action", None),
            ("valid_action", "invalid_result"),
            ("valid_action", {"r√©ussite": "invalid_boolean"}),
            ("valid_action", {"r√©ussite": True, "score_gagne": "invalid_number"}),
        ]

        for action, result in invalid_inputs:
            with self.subTest(action=action, result=result):
                try:
                    # Le moteur devrait g√©rer gracieusement les donn√©es invalides
                    if action and result:
                        # Simulation d'une action valide
                        self.assertTrue(True)
                    else:
                        # Simulation d'une gestion d'erreur
                        self.assertTrue(True)
                except Exception:
                    # Si une erreur se produit, elle devrait √™tre g√©r√©e gracieusement
                    self.assertTrue(True)

    # ===== TESTS D'INT√âGRATION AVEC LA BASE DE DONN√âES =====

    def test_data_persistence_validation(self):
        """Test de validation de la persistance des donn√©es"""
        print("üíæ Test de validation de la persistance...")

        # Test de sauvegarde des profils
        test_profile = self.test_profiles["debutant"].copy()
        test_profile["username"] = "test_persistence_user"

        # Simuler la sauvegarde
        try:
            # V√©rifier que le profil peut √™tre sauvegard√©
            self.assertIsInstance(test_profile, dict)
            self.assertIn("username", test_profile)
            self.assertIn("score", test_profile)
            self.assertIn("level", test_profile)

            # V√©rifier la coh√©rence des donn√©es
            self.assertGreaterEqual(test_profile["level"], 1)
            self.assertGreaterEqual(test_profile["score"], 0)
            self.assertIsInstance(test_profile["badges"], list)
            self.assertIsInstance(test_profile["achievements"], list)

        except Exception:
            self.fail("La sauvegarde du profil devrait fonctionner")

    def test_leaderboard_integration(self):
        """Test d'int√©gration avec le syst√®me de classement"""
        print("üèÜ Test d'int√©gration avec le classement...")

        # Cr√©er des profils de test pour le classement
        leaderboard_profiles = [
            {"username": "player1", "score": 1000, "level": 3},
            {"username": "player2", "score": 2500, "level": 5},
            {"username": "player3", "score": 500, "level": 2},
            {"username": "player4", "score": 3000, "level": 6},
        ]

        # Trier par score (classement)
        sorted_profiles = sorted(
            leaderboard_profiles, key=lambda x: x["score"], reverse=True
        )

        # V√©rifier le classement
        self.assertEqual(sorted_profiles[0]["username"], "player4")
        self.assertEqual(sorted_profiles[0]["score"], 3000)
        self.assertEqual(sorted_profiles[-1]["username"], "player3")
        self.assertEqual(sorted_profiles[-1]["score"], 500)

        # V√©rifier la coh√©rence
        for i in range(1, len(sorted_profiles)):
            self.assertGreaterEqual(
                sorted_profiles[i - 1]["score"],
                sorted_profiles[i]["score"],
                "Le classement devrait √™tre d√©croissant",
            )

    # ===== TESTS DE VALIDATION DES R√âCOMPENSES =====

    def test_reward_balance_validation(self):
        """Test de validation de l'√©quilibrage des r√©compenses"""
        print("‚öñÔ∏è Test de validation de l'√©quilibrage...")

        # Test de l'√©quilibrage des points
        reward_categories = {
            "missions": {"base": 100, "bonus": 50, "max": 200},
            "badges": {"base": 200, "bonus": 100, "max": 500},
            "achievements": {"base": 150, "bonus": 75, "max": 300},
            "social": {"base": 75, "bonus": 25, "max": 150},
        }

        for category, rewards in reward_categories.items():
            with self.subTest(category=category):
                # V√©rifier la coh√©rence des r√©compenses
                self.assertGreater(rewards["base"], 0)
                self.assertGreaterEqual(rewards["bonus"], 0)
                self.assertGreaterEqual(rewards["max"], rewards["base"])

                # V√©rifier que les bonus ne d√©passent pas le maximum
                total_reward = rewards["base"] + rewards["bonus"]
                self.assertLessEqual(total_reward, rewards["max"])

    def test_progression_curve_validation(self):
        """Test de validation de la courbe de progression"""
        print("üìà Test de validation de la courbe de progression...")

        # Test de la progression des niveaux
        level_progression = []
        for score in range(0, 10000, 100):
            level = self.calculate_level_from_score(score)
            level_progression.append({"score": score, "level": level})

        # V√©rifier que la progression est logique
        for i in range(1, len(level_progression)):
            current = level_progression[i]
            previous = level_progression[i - 1]

            # Le niveau devrait augmenter ou rester stable
            self.assertGreaterEqual(current["level"], previous["level"])

            # La progression devrait √™tre r√©guli√®re
            if current["score"] - previous["score"] >= 500:
                self.assertGreaterEqual(current["level"], previous["level"] + 1)

    # ===== TESTS DE STRESS ET LIMITES =====

    def test_stress_test_extreme_values(self):
        """Test de stress avec des valeurs extr√™mes"""
        print("üî• Test de stress avec valeurs extr√™mes...")

        # Test avec des valeurs extr√™mes
        extreme_cases = [
            {"score": 999999999, "expected_level": 100},
            {"badges": ["badge"] * 1000, "expected_count": 1000},
            {"achievements": ["achievement"] * 500, "expected_count": 500},
            {"streak": 365, "expected_streak": 365},
        ]

        for case in extreme_cases:
            with self.subTest(case=case):
                try:
                    if "score" in case:
                        level = self.calculate_level_from_score(case["score"])
                        self.assertEqual(level, case["expected_level"])
                    elif "badges" in case:
                        self.assertEqual(len(case["badges"]), case["expected_count"])
                    elif "achievements" in case:
                        self.assertEqual(
                            len(case["achievements"]), case["expected_count"]
                        )
                    elif "streak" in case:
                        self.assertEqual(case["streak"], case["expected_streak"])

                except Exception as e:
                    self.fail(f"Le syst√®me devrait g√©rer les valeurs extr√™mes: {e}")

    def test_concurrent_access_simulation(self):
        """Test de simulation d'acc√®s concurrent"""
        print("üîÑ Test de simulation d'acc√®s concurrent...")

        # Simuler des acc√®s concurrents
        import threading

        results = []
        errors = []

        def worker(worker_id):
            try:
                for i in range(10):
                    # Simuler des op√©rations de gamification
                    profile = self.test_profiles["intermediaire"].copy()
                    profile["username"] = f"worker_{worker_id}"
                    profile["score"] += i * 10
                    profile["level"] = self.calculate_level_from_score(profile["score"])

                    results.append((worker_id, i, profile))
            except Exception as e:
                errors.append((worker_id, e))

        # Lancer 5 threads concurrents
        threads = []
        for i in range(5):
            thread = threading.Thread(target=worker, args=(i,))
            threads.append(thread)
            thread.start()

        # Attendre la fin de tous les threads
        for thread in threads:
            thread.join()

        # V√©rifier qu'il n'y a pas d'erreurs
        self.assertEqual(
            len(errors), 0, f"Erreurs lors de l'acc√®s concurrent: {errors}"
        )

        # V√©rifier que tous les r√©sultats sont valides
        self.assertEqual(
            len(results), 50, "Tous les threads devraient avoir produit des r√©sultats"
        )

        for _worker_id, _iteration, profile in results:
            self.assertIsInstance(profile, dict)
            self.assertIn("username", profile)
            self.assertIn("score", profile)
            self.assertIn("level", profile)

    # ===== TESTS DE VALIDATION FINALE =====

    def test_final_validation_complete_system(self):
        """Test de validation finale du syst√®me complet"""
        print("üéØ Test de validation finale du syst√®me complet...")

        # Test complet du syst√®me de gamification
        test_profile = self.test_profiles["debutant"].copy()
        test_profile["username"] = "final_test_user"

        # S√©quence compl√®te d'actions de gamification
        gamification_sequence = [
            ("start_game", {"action": "start", "bonus": 0}),
            ("complete_tutorial", {"action": "tutorial", "bonus": 100}),
            ("first_mission", {"action": "mission", "bonus": 150}),
            ("earn_badge", {"action": "badge", "bonus": 200}),
            ("social_interaction", {"action": "social", "bonus": 75}),
            ("daily_login", {"action": "login", "bonus": 25}),
            ("achievement_unlock", {"action": "achievement", "bonus": 300}),
            ("level_up", {"action": "level", "bonus": 100}),
            ("session_end", {"action": "end", "bonus": 0}),
        ]

        gamification_history = []

        for action, details in gamification_sequence:
            # Simuler l'action
            test_profile["score"] += details["bonus"]
            test_profile["level"] = self.calculate_level_from_score(
                test_profile["score"]
            )

            # Enregistrer l'historique
            gamification_history.append(
                {
                    "action": action,
                    "score": test_profile["score"],
                    "level": test_profile["level"],
                    "bonus": details["bonus"],
                },
            )

        # Validations finales
        self.assertEqual(len(gamification_history), len(gamification_sequence))

        # V√©rifier la progression du score
        final_score = sum(record["bonus"] for record in gamification_history)
        self.assertEqual(test_profile["score"], final_score)

        # V√©rifier la progression du niveau
        final_level = self.calculate_level_from_score(final_score)
        self.assertEqual(test_profile["level"], final_level)

        # V√©rifier la coh√©rence des donn√©es
        self.assertGreater(test_profile["score"], 0)
        self.assertGreater(test_profile["level"], 1)
        self.assertIsInstance(test_profile["badges"], list)
        self.assertIsInstance(test_profile["achievements"], list)

        # V√©rifier que le syst√®me est √©quilibr√©
        self.assertGreaterEqual(final_score, 950)  # Score minimum attendu
        self.assertGreaterEqual(final_level, 3)  # Niveau minimum attendu


if __name__ == "__main__":
    # Configuration des tests
    unittest.main(
        verbosity=2,
        failfast=False,
        buffer=True,
    )
