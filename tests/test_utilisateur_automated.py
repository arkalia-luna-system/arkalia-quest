#!/usr/bin/env python3
"""
Test automatisÃ© pour validation utilisateur d'Arkalia Quest
ComplÃ¨te les tests manuels avec des vÃ©rifications automatiques
"""

import json
import os
import sys
from datetime import datetime

# Ajouter le rÃ©pertoire parent au path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


class TestUtilisateurAutomated:
    """Classe pour les tests automatisÃ©s de validation utilisateur"""

    def __init__(self):
        self.results = {
            "timestamp": datetime.now().isoformat(),
            "tests": {},
            "summary": {},
        }

    def test_interface_responsive(self):
        """Test de la responsivitÃ© de l'interface"""
        print("ğŸ“± Test de responsivitÃ©...")

        # VÃ©rifier que les fichiers CSS responsive existent
        css_files = ["static/css/responsive.css", "static/css/arkalia-luna-vision.css"]

        responsive_ok = True
        for css_file in css_files:
            if not os.path.exists(css_file):
                print(f"âŒ {css_file} manquant")
                responsive_ok = False
            else:
                print(f"âœ… {css_file} prÃ©sent")

        self.results["tests"]["responsive"] = {
            "status": "pass" if responsive_ok else "fail",
            "details": (
                "Fichiers CSS responsive prÃ©sents"
                if responsive_ok
                else "Fichiers CSS manquants"
            ),
        }
        return responsive_ok

    def test_accessibility(self):
        """Test des fonctionnalitÃ©s d'accessibilitÃ©"""
        print("â™¿ Test d'accessibilitÃ©...")

        # VÃ©rifier les fichiers d'accessibilitÃ©
        accessibility_files = [
            "static/css/accessibility.css",
            "static/js/accessibility.js",
        ]

        accessibility_ok = True
        for file in accessibility_files:
            if not os.path.exists(file):
                print(f"âŒ {file} manquant")
                accessibility_ok = False
            else:
                print(f"âœ… {file} prÃ©sent")

        # VÃ©rifier le contenu du fichier CSS d'accessibilitÃ©
        if os.path.exists("static/css/accessibility.css"):
            with open("static/css/accessibility.css", "r") as f:
                content = f.read()
                if "contrast" in content.lower() and "focus" in content.lower():
                    print("âœ… Styles d'accessibilitÃ© dÃ©tectÃ©s")
                else:
                    print("âš ï¸ Styles d'accessibilitÃ© limitÃ©s")
                    accessibility_ok = False

        self.results["tests"]["accessibility"] = {
            "status": "pass" if accessibility_ok else "fail",
            "details": (
                "FonctionnalitÃ©s d'accessibilitÃ© prÃ©sentes"
                if accessibility_ok
                else "FonctionnalitÃ©s d'accessibilitÃ© manquantes"
            ),
        }
        return accessibility_ok

    def test_performance_files(self):
        """Test de la performance des fichiers"""
        print("âš¡ Test de performance...")

        # VÃ©rifier la taille des fichiers principaux
        files_to_check = [
            "static/js/mini-games-interface.js",
            "static/css/arkalia-luna-vision.css",
            "static/js/terminal.js",
        ]

        performance_ok = True
        for file_path in files_to_check:
            if os.path.exists(file_path):
                size = os.path.getsize(file_path)
                size_kb = size / 1024
                print(f"ğŸ“Š {file_path}: {size_kb:.1f} KB")

                # VÃ©rifier que les fichiers ne sont pas trop lourds
                if size_kb > 100:  # Plus de 100KB
                    print(f"âš ï¸ {file_path} est assez lourd ({size_kb:.1f} KB)")
                else:
                    print(f"âœ… {file_path} taille acceptable")
            else:
                print(f"âŒ {file_path} manquant")
                performance_ok = False

        self.results["tests"]["performance"] = {
            "status": "pass" if performance_ok else "fail",
            "details": (
                "Fichiers de taille acceptable"
                if performance_ok
                else "ProblÃ¨mes de taille de fichiers"
            ),
        }
        return performance_ok

    def test_content_quality(self):
        """Test de la qualitÃ© du contenu"""
        print("ğŸ“š Test de qualitÃ© du contenu...")

        # VÃ©rifier les missions
        missions_dir = "data/missions"
        missions_ok = True

        if os.path.exists(missions_dir):
            mission_files = [f for f in os.listdir(missions_dir) if f.endswith(".json")]
            print(f"ğŸ“‹ {len(mission_files)} missions trouvÃ©es")

            for mission_file in mission_files:
                try:
                    with open(
                        os.path.join(missions_dir, mission_file), "r", encoding="utf-8"
                    ) as f:
                        mission = json.load(f)

                    # VÃ©rifier la structure de la mission
                    required_fields = [
                        "id",
                        "title",
                        "description",
                        "difficulty",
                        "steps",
                    ]
                    for field in required_fields:
                        if field not in mission:
                            print(f"âŒ {mission_file}: champ '{field}' manquant")
                            missions_ok = False

                    if missions_ok:
                        print(f"âœ… {mission_file}: structure correcte")

                except Exception as e:
                    print(f"âŒ Erreur lecture {mission_file}: {e}")
                    missions_ok = False
        else:
            print("âŒ Dossier missions manquant")
            missions_ok = False

        # VÃ©rifier les badges
        badges_ok = True
        if os.path.exists("data/badges_secrets.json"):
            try:
                with open("data/badges_secrets.json", "r", encoding="utf-8") as f:
                    badges = json.load(f)

                if "badges_secrets" in badges:
                    badge_count = len(badges["badges_secrets"])
                    print(f"ğŸ† {badge_count} badges trouvÃ©s")

                    if badge_count >= 10:
                        print("âœ… Nombre de badges suffisant")
                    else:
                        print("âš ï¸ Peu de badges disponibles")
                        badges_ok = False
                else:
                    print("âŒ Structure badges incorrecte")
                    badges_ok = False

            except Exception as e:
                print(f"âŒ Erreur lecture badges: {e}")
                badges_ok = False
        else:
            print("âŒ Fichier badges manquant")
            badges_ok = False

        content_ok = missions_ok and badges_ok
        self.results["tests"]["content_quality"] = {
            "status": "pass" if content_ok else "fail",
            "details": "Contenu de qualitÃ©" if content_ok else "ProblÃ¨mes de contenu",
        }
        return content_ok

    def test_educational_value(self):
        """Test de la valeur Ã©ducative"""
        print("ğŸ“ Test de valeur Ã©ducative...")

        try:
            from core.educational_games_engine import EducationalGamesEngine

            ege = EducationalGamesEngine()
            games = ege.get_available_games(1)

            print(f"ğŸ® {len(games)} mini-jeux disponibles")

            # Analyser les types de jeux
            game_types = {}
            for game in games:
                game_type = game.get("type", "unknown")
                game_types[game_type] = game_types.get(game_type, 0) + 1

            print("ğŸ“Š Types de jeux:")
            for game_type, count in game_types.items():
                print(f"  - {game_type}: {count} jeux")

            # VÃ©rifier la diversitÃ©
            if len(game_types) >= 3:
                print("âœ… DiversitÃ© des types de jeux")
                educational_ok = True
            else:
                print("âš ï¸ Peu de diversitÃ© dans les types de jeux")
                educational_ok = False

            # VÃ©rifier les points
            total_points = sum(game.get("points", 0) for game in games)
            print(f"ğŸ¯ Total points disponibles: {total_points}")

            if total_points >= 500:
                print("âœ… SystÃ¨me de points Ã©quilibrÃ©")
            else:
                print("âš ï¸ Peu de points disponibles")
                educational_ok = False

        except Exception as e:
            print(f"âŒ Erreur test Ã©ducatif: {e}")
            educational_ok = False

        self.results["tests"]["educational_value"] = {
            "status": "pass" if educational_ok else "fail",
            "details": (
                "Valeur Ã©ducative Ã©levÃ©e"
                if educational_ok
                else "Valeur Ã©ducative limitÃ©e"
            ),
        }
        return educational_ok

    def run_all_tests(self):
        """ExÃ©cute tous les tests automatisÃ©s"""
        print("ğŸš€ TESTS AUTOMATISÃ‰S DE VALIDATION UTILISATEUR")
        print("=" * 60)

        tests = [
            ("Interface Responsive", self.test_interface_responsive),
            ("AccessibilitÃ©", self.test_accessibility),
            ("Performance", self.test_performance_files),
            ("QualitÃ© du Contenu", self.test_content_quality),
            ("Valeur Ã‰ducative", self.test_educational_value),
        ]

        results = []
        for test_name, test_func in tests:
            print(f"\nğŸ” {test_name}...")
            try:
                result = test_func()
                results.append(result)
                print(
                    f"{'âœ…' if result else 'âŒ'} {test_name}: {'PASS' if result else 'FAIL'}"
                )
            except Exception as e:
                print(f"ğŸ’¥ Erreur dans {test_name}: {e}")
                results.append(False)

        # RÃ©sumÃ©
        passed = sum(results)
        total = len(results)

        print("\n" + "=" * 60)
        print("ğŸ“Š RÃ‰SULTATS DES TESTS AUTOMATISÃ‰S:")
        print(f"âœ… Tests rÃ©ussis: {passed}/{total}")
        print(f"âŒ Tests Ã©chouÃ©s: {total - passed}/{total}")

        self.results["summary"] = {
            "total_tests": total,
            "passed_tests": passed,
            "failed_tests": total - passed,
            "success_rate": (passed / total) * 100 if total > 0 else 0,
        }

        if passed == total:
            print("\nğŸ‰ TOUS LES TESTS AUTOMATISÃ‰S SONT PASSÃ‰S !")
            print("âœ… Le jeu est prÃªt pour les tests utilisateur manuels")
        else:
            print(f"\nâš ï¸ {total - passed} test(s) ont Ã©chouÃ©")
            print("ğŸ”§ Des corrections sont nÃ©cessaires avant les tests utilisateur")

        return passed == total

    def save_report(self, filename="test_utilisateur_automated_report.json"):
        """Sauvegarde le rapport de test"""
        report_path = os.path.join("tests", "reports", filename)
        os.makedirs(os.path.dirname(report_path), exist_ok=True)

        with open(report_path, "w", encoding="utf-8") as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ“„ Rapport sauvegardÃ©: {report_path}")


def main():
    """Fonction principale"""
    tester = TestUtilisateurAutomated()
    success = tester.run_all_tests()
    tester.save_report()

    return 0 if success else 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
